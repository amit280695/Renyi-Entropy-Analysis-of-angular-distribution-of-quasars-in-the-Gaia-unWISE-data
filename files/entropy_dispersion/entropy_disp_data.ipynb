{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a689e974-6514-496e-86fb-db1a147930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import healpy as hp\n",
    "from statistics import stdev, mean\n",
    "\n",
    "nside = 8   # this is for masking 1 and masking 2\n",
    "nf = 100  # number of samples\n",
    "\n",
    "# Compute RÃ©nyi entropies for q = 1 to 5\n",
    "\n",
    "def compute_renyi_entropy(input_file, output_file,rmin, rmax, Nside= nside, nbin=30):\n",
    "    Npix = hp.nside2npix(Nside)\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(input_file, sep=\"\\t\", header=None)\n",
    "    df.columns = ['r', 'th', 'ph']\n",
    "    r1 = df['r'].to_numpy()\n",
    "    th1 = df['th'].to_numpy()\n",
    "    ph1 = df['ph'].to_numpy()\n",
    "\n",
    "\n",
    "    #rmin, rmax = np.min(r1), np.max(r1)\n",
    "    dr = (rmax - rmin) / nbin\n",
    "\n",
    "    m = np.zeros((nbin, Npix), dtype=float)\n",
    "    Neff = np.zeros(nbin, dtype=int)\n",
    "\n",
    "    for rr, tt, pp in zip(r1, th1, ph1):\n",
    "        for j in range(nbin):\n",
    "            if rmin <= rr <= (rmin + (j+1) * dr):\n",
    "                px = hp.ang2pix(Nside, tt, pp)\n",
    "                m[j][px] += 1\n",
    "                Neff[j] += 1\n",
    "\n",
    "    p = np.zeros((nbin, Npix), dtype=float)\n",
    "    for i in range(nbin):\n",
    "        for px in range(Npix):\n",
    "            if Neff[i] > 0:\n",
    "                p[i][px] = m[i][px] / Neff[i]\n",
    "\n",
    "    H = np.zeros((nbin, 5), dtype=float)\n",
    "    a = np.zeros((nbin, 5), dtype=float)\n",
    "    \n",
    "    for k in range(5):\n",
    "        h = np.zeros(nbin, dtype=float)\n",
    "        q = k + 1\n",
    "        if q == 1:\n",
    "            for i in range(nbin):\n",
    "                for px in range(Npix):\n",
    "                    if p[i][px] > 0:\n",
    "                        H[i][k] -= p[i][px] * np.log10(p[i][px])\n",
    "        else:\n",
    "            for i in range(nbin):\n",
    "                for px in range(Npix):\n",
    "                    h[i] += p[i][px] ** q\n",
    "                if h[i] > 0:\n",
    "                    H[i][k] = np.log10(h[i]) / (1 - q)\n",
    "\n",
    "        for i in range(nbin):\n",
    "            a[i][k] = H[i][k]\n",
    "\n",
    "    R = np.zeros(nbin)\n",
    "    for b in range(nbin):\n",
    "        R[b] = rmin + (b+1)*dr\n",
    "        \n",
    "    df1=pd.DataFrame(data=a)\n",
    "    df2=pd.DataFrame(data=R)\n",
    "    df3= pd.concat([df2,df1], axis=1, join='inner')\n",
    "    df3.to_csv(output_file, sep='\\t', header=False, index=False)\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "R_max = np.zeros(3)\n",
    "R_min = np.zeros(3)\n",
    "\n",
    "for n in range(3):\n",
    "    f_in = '../data_prep/mask1/masked_sample_' + str(n+1) + '.dat'\n",
    "    # f_in = '../data_prep/mask2/masked_sample_' + str(n+1) + '.dat'\n",
    "    \n",
    "    df = pd.read_csv(f_in,sep=\"\\t\",header = None)\n",
    "    df.columns = ['r','th','ph']\n",
    "    R_max[n] = df['r'].max()\n",
    "    R_min[n] = df['r'].min()\n",
    "\n",
    "    f_out1 = 'renyi_anis_s'+ str(n+1)+'.dat'\n",
    "    compute_renyi_entropy(f_in, f_out1,R_min[n],R_max[n])\n",
    "    \n",
    "    \n",
    "    for l in range(nf):\n",
    "        fd=df.sample(frac=0.8,replace=True,random_state = l)\n",
    "        f_samp = 'sample'+ str(n+1) + '_' + str(l+1) + '.dat' \n",
    "        fd.to_csv(f_samp,sep=\"\\t\",header = None,index = False)\n",
    "        f_out2 = 'anis_s'+ str(n+1) + '_' + str (l+1) + '.dat'\n",
    "        compute_renyi_entropy(f_samp,f_out2,R_min[n],R_max[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df163ae-096e-44b9-af3c-6e8d99ca503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of normalized entropy dispersion and error associated with it\n",
    "\n",
    "for n in range(3):\n",
    "    file_in = 'renyi_anis_s'+ str(n+1)+'.dat'\n",
    "    data = np.loadtxt(file_in)\n",
    "    r = data[:, 0]\n",
    "    samples = data[:, 1:6]\n",
    "\n",
    "    s_mean = np.mean(samples, axis=1)\n",
    "    stab_cri = np.std(samples, axis=1, ddof=0)\n",
    "    frac_cri = stab_cri / s_mean\n",
    "\n",
    "    df = pd.DataFrame({'r': r, 'crit': frac_cri})\n",
    "    file_out = 'sample'+ str(n+1)+'_crit.csv'\n",
    "    df.to_csv(file_out, index=False)\n",
    "\n",
    "\n",
    "for n in range(3):\n",
    "    df_crit = pd.read_csv('sample'+ str(n+1)+'_crit.csv')\n",
    "    r = df_crit['r'].to_numpy()\n",
    "    crit_mean = df_crit['crit'].to_numpy()\n",
    "    nbin = len(r)\n",
    "\n",
    "    criteria = np.zeros((nf, nbin))\n",
    "\n",
    "    for f in range(nf):\n",
    "        file = 'anis_s'+ str(n+1) + '_' + str (f+1) + '.dat'\n",
    "        data = np.loadtxt(file)\n",
    "        samples = data[:, 1:6]\n",
    "        mean_vals = np.mean(samples, axis=1)\n",
    "        stab_vals = np.std(samples, axis=1, ddof=0)\n",
    "        criteria[f] = stab_vals / mean_vals\n",
    "\n",
    "    # Compute std across samples at each radius bin\n",
    "    crit_std = np.std(criteria, axis=0, ddof=1)\n",
    "\n",
    "    df_out = pd.DataFrame({'r': r, 'crit': crit_mean, 'sd': crit_std})\n",
    "    df_out.to_csv('sample_'+str(n+1)+'_criteria_err.csv' , index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db58736-c261-4485-90ca-90b3470dd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for n in range(3):\n",
    "    f_out1 = 'renyi_anis_s'+ str(n+1)+'.dat'\n",
    "    os.remove(f_out1)\n",
    "    f_out2 = 'sample'+ str(n+1)+'_crit.csv'\n",
    "    os.remove(f_out2)\n",
    "    for l in range(nf):\n",
    "        file_name = 'anis_s'+ str(n+1) + '_' + str (l+1) + '.dat'\n",
    "        os.remove(file_name)\n",
    "        f_samp = 'sample'+ str(n+1) + '_' + str(l+1) + '.dat' \n",
    "        os.remove(f_samp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
